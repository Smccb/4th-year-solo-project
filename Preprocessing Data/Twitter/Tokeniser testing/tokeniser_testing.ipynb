{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the dataset\n",
    "dataset = pd.read_json(\"../data_without_hashtags.json\")\n",
    "\n",
    "# Split the indices of the DataFrame into two halves with stratified sampling\n",
    "indices_half1, indices_half2 = train_test_split(dataset.index, test_size=0.5, stratify=dataset['isSarcastic'], random_state=42)\n",
    "\n",
    "# Create DataFrame quarters using the selected indices\n",
    "dataset_half = dataset.loc[indices_half1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_half['text'], dataset_half['isSarcastic'], test_size=0.2, random_state=42)\n",
    "\n",
    "#dataset = dataset_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#tokeniser testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Is the keras default one I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset['isSarcastic'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (15912, 140)\n",
      "Shape of X_test: (3978, 140)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Read the dataset\n",
    "#dataset = pd.read_json(\"data_without_hashtags.json\")\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize and vectorize the training text data using Tokenizer and pad_sequences\n",
    "max_length = 140\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "\n",
    "#y_train_categorical = to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Display the shapes of the resulting matrices\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# Tokenize and vectorize the testing text data using the same Tokenizer\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Display the shape of X_test\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#this is keras but it does not lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset['isSarcastic'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (31824, 140)\n",
      "Shape of X_test: (7956, 140)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Read the dataset\n",
    "#dataset = pd.read_json(\"data_without_hashtags.json\")\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize and vectorize the training text data using Tokenizer and pad_sequences\n",
    "max_length = 140\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "\n",
    "#y_train_categorical = to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Display the shapes of the resulting matrices\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# Tokenize and vectorize the testing text data using the same Tokenizer\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Display the shape of X_test\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Read the dataset\n",
    "#dataset = pd.read_json(\"data_without_hashtags.json\")\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize and vectorize the training text data using Tokenizer and pad_sequences\n",
    "max_length = 140\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "\n",
    "#y_train_categorical = to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Display the shapes of the resulting matrices\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# Tokenize and vectorize the testing text data using the same Tokenizer\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Display the shape of X_test\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    pos_tags = pos_tag(tokens)    # Perform POS tagging\n",
    "    return pos_tags\n",
    "\n",
    "dataset['pos_tags'] = dataset['text'].apply(pos_tag_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['pos_tags'], dataset['isSarcastic'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (31824,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X_test_processed \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mapply(pos_tag_features)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Convert to NumPy arrays\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m X_test_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test_processed\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (31824,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Convert POS tagged tokens into features\n",
    "def pos_tag_features(pos_tags):\n",
    "    features = []\n",
    "    for word, pos_tag in pos_tags:\n",
    "        features.append(pos_tag)  # For demonstration, just using the POS tag itself\n",
    "    return features\n",
    "\n",
    "# Preprocess X_train and X_test\n",
    "X_train_processed = X_train.apply(pos_tag_features)\n",
    "X_test_processed = X_test.apply(pos_tag_features)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train_array = np.array(X_train_processed.tolist())\n",
    "X_test_array = np.array(X_test_processed.tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "m1.fit(X_train_array, y_train, epochs=10, batch_size=64, validation_data=(X_test_array, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = m1.evaluate(X_test_array, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#embeddings layer added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "# Assuming you have already defined X_train, X_test, y_train, and y_test\n",
    "\n",
    "# Tokenize and vectorize the training text data using Tokenizer and pad_sequences\n",
    "max_length = 140\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "\n",
    "# Tokenize and vectorize the testing text data using the same Tokenizer\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "     ---------------------------------------- 0.0/85.1 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 41.0/85.1 kB 1.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 41.0/85.1 kB 1.9 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 61.4/85.1 kB 409.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 85.1/85.1 kB 476.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.16.3-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Downloading spacy-3.7.4-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.1/12.1 MB 819.2 kB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.1/12.1 MB 944.1 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.2/12.1 MB 807.1 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.2/12.1 MB 885.4 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.3/12.1 MB 1.0 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.4/12.1 MB 1.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.5/12.1 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.5/12.1 MB 994.6 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.5/12.1 MB 962.6 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.6/12.1 MB 1.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.6/12.1 MB 992.1 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/12.1 MB 992.1 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/12.1 MB 983.8 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/12.1 MB 982.7 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/12.1 MB 996.7 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/12.1 MB 964.6 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/12.1 MB 953.7 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.9/12.1 MB 938.1 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 0.9/12.1 MB 940.5 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 0.9/12.1 MB 940.5 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/12.1 MB 933.6 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/12.1 MB 886.4 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/12.1 MB 859.2 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/12.1 MB 894.7 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.1/12.1 MB 873.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.1/12.1 MB 860.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.2/12.1 MB 886.7 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.2/12.1 MB 886.7 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.2/12.1 MB 871.3 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 871.3 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 884.9 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 880.4 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 880.1 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 859.5 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 859.5 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 859.5 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.5/12.1 MB 820.6 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 860.7 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 850.2 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 850.2 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 821.7 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 806.7 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 806.7 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 806.0 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.8/12.1 MB 826.4 kB/s eta 0:00:13\n",
      "   ------ --------------------------------- 1.9/12.1 MB 839.9 kB/s eta 0:00:13\n",
      "   ------ --------------------------------- 1.9/12.1 MB 843.4 kB/s eta 0:00:13\n",
      "   ------ --------------------------------- 2.0/12.1 MB 841.5 kB/s eta 0:00:13\n",
      "   ------ --------------------------------- 2.0/12.1 MB 859.5 kB/s eta 0:00:12\n",
      "   ------ --------------------------------- 2.1/12.1 MB 870.9 kB/s eta 0:00:12\n",
      "   ------- -------------------------------- 2.2/12.1 MB 913.2 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.3/12.1 MB 925.7 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.3/12.1 MB 925.7 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.4/12.1 MB 919.3 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.5/12.1 MB 926.7 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.5/12.1 MB 936.9 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.5/12.1 MB 925.1 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.6/12.1 MB 938.4 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.7/12.1 MB 955.5 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.8/12.1 MB 963.5 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.8/12.1 MB 976.1 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.9/12.1 MB 993.7 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 3.0/12.1 MB 1.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 3.1/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.3/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.5/12.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.6/12.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.7/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.7/12.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.8/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.8/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.9/12.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.0/12.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.0/12.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.1/12.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.1/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.1/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.1/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.1 MB 997.5 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.3/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.4/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.5/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.5/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.5/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.6/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.6/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.7/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.8/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.8/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.8/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 5.0/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.4/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.4/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.4/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.5/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.6/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.6/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.7/12.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 5.8/12.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.9/12.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.9/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.9/12.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.1/12.1 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.2/12.1 MB 995.4 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.2/12.1 MB 991.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.2/12.1 MB 991.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.2/12.1 MB 991.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 980.6 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 985.4 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 985.4 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 969.0 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 969.0 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 969.0 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.1 MB 969.0 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.4/12.1 MB 951.7 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.5/12.1 MB 955.7 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.5/12.1 MB 958.2 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.5/12.1 MB 956.8 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.6/12.1 MB 950.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.6/12.1 MB 951.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 951.6 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 959.8 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 957.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 957.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 952.2 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 944.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 944.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 944.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 944.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.9/12.1 MB 931.9 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 937.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 945.5 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 945.5 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 939.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 910.8 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 908.4 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 907.4 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 900.6 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.3/12.1 MB 906.0 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.3/12.1 MB 903.3 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.3/12.1 MB 901.1 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.4/12.1 MB 902.2 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.4/12.1 MB 902.2 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.5/12.1 MB 900.2 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.5/12.1 MB 903.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.5/12.1 MB 903.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.5/12.1 MB 894.9 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.6/12.1 MB 893.5 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.6/12.1 MB 895.6 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.6/12.1 MB 890.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.6/12.1 MB 890.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.6/12.1 MB 884.5 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.7/12.1 MB 882.1 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.7/12.1 MB 877.7 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.8/12.1 MB 882.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 882.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 882.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 869.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 867.4 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 867.4 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 860.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.8/12.1 MB 860.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.9/12.1 MB 859.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.9/12.1 MB 863.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 864.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 859.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 861.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 861.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 861.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 861.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 840.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 840.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 840.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 840.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.0/12.1 MB 840.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 825.5 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 825.5 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 825.5 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 825.5 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 810.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 810.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 810.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 810.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.1/12.1 MB 796.7 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 796.7 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 796.7 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 796.7 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 784.5 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 784.5 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 784.5 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 784.5 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.1/12.1 MB 773.4 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 8.2/12.1 MB 774.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 772.5 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 772.5 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 772.5 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 772.5 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 762.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 762.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 762.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 762.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 748.9 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 748.9 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 748.9 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 748.9 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 737.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 737.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.2/12.1 MB 737.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.3/12.1 MB 731.7 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.3/12.1 MB 730.4 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.3/12.1 MB 729.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.3/12.1 MB 726.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.3/12.1 MB 727.8 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 729.4 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 726.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 726.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 726.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 726.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 726.3 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 8.4/12.1 MB 714.4 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 8.5/12.1 MB 716.1 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 8.5/12.1 MB 715.6 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.6/12.1 MB 717.3 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.6/12.1 MB 720.3 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 719.3 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 719.1 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 719.1 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 713.5 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 713.4 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 713.8 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 715.3 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 715.1 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 719.8 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 9.0/12.1 MB 722.8 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 9.1/12.1 MB 724.2 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 9.1/12.1 MB 727.3 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 9.2/12.1 MB 730.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.2/12.1 MB 730.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.2/12.1 MB 730.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.2/12.1 MB 725.3 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.3/12.1 MB 729.9 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.4/12.1 MB 735.3 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 734.2 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 731.4 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 732.2 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 730.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 730.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 730.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 725.6 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 725.6 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 722.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.5/12.1 MB 722.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 716.0 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 716.0 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 716.0 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 712.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 709.1 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 9.6/12.1 MB 709.1 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.7/12.1 MB 710.3 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.7/12.1 MB 710.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.7/12.1 MB 711.5 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.8/12.1 MB 712.6 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.8/12.1 MB 712.6 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.9/12.1 MB 713.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.0/12.1 MB 719.5 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.0/12.1 MB 719.5 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.1/12.1 MB 718.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.2/12.1 MB 723.2 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.2/12.1 MB 723.2 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.3/12.1 MB 725.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.4/12.1 MB 732.3 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.4/12.1 MB 734.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 734.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 732.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 731.5 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 729.1 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.7/12.1 MB 726.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.7/12.1 MB 732.4 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 729.1 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 730.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 732.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.9/12.1 MB 730.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.0/12.1 MB 731.5 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.0/12.1 MB 734.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.2/12.1 MB 741.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.3/12.1 MB 749.1 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.3/12.1 MB 751.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.3/12.1 MB 751.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.4/12.1 MB 751.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 755.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 757.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 767.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.1 MB 769.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 779.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 779.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 777.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 776.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 774.6 kB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 112.6/181.6 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 181.6/181.6 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.2 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 61.4/122.2 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 122.2/122.2 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "   ---------------------------------------- 0.0/394.9 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/394.9 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 143.4/394.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 235.5/394.9 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 307.2/394.9 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 337.9/394.9 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 394.9/394.9 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.9/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.4/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-win_amd64.whl (481 kB)\n",
      "   ---------------------------------------- 0.0/481.9 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 112.6/481.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 225.3/481.9 kB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 327.7/481.9 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  481.3/481.9 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 481.9/481.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 30.7/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/6.6 MB 7.0 MB/s eta 0:00:01\n",
      "    --------------------------------------- 0.2/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/6.6 MB 2.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/6.6 MB 2.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/6.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.8/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.0/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.1/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.1/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.4/6.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.6/6.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.6/6.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.8/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.0/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.1/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.2/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.3/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.3/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.4/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.8/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.9/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.0/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.1/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.2/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.3/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.3/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.5/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.5/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.6/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.8/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.8/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.0/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.0/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.1/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.3/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.4/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.6/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.8/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.0/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.0/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.1/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.3/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.6/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.6/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.9/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.0/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.3/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.6.4 pydantic-core-2.16.3 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 393.8 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 744.7 kB/s eta 0:00:18\n",
      "     --------------------------------------- 0.1/12.8 MB 654.9 kB/s eta 0:00:20\n",
      "      -------------------------------------- 0.2/12.8 MB 871.5 kB/s eta 0:00:15\n",
      "      -------------------------------------- 0.2/12.8 MB 692.4 kB/s eta 0:00:19\n",
      "      -------------------------------------- 0.3/12.8 MB 842.9 kB/s eta 0:00:15\n",
      "     - ------------------------------------- 0.3/12.8 MB 910.2 kB/s eta 0:00:14\n",
      "     - ------------------------------------- 0.4/12.8 MB 969.0 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.4/12.8 MB 946.4 kB/s eta 0:00:14\n",
      "     - ------------------------------------- 0.5/12.8 MB 880.6 kB/s eta 0:00:15\n",
      "     - ------------------------------------- 0.5/12.8 MB 898.6 kB/s eta 0:00:14\n",
      "     - ------------------------------------- 0.5/12.8 MB 862.0 kB/s eta 0:00:15\n",
      "     - ------------------------------------- 0.5/12.8 MB 862.0 kB/s eta 0:00:15\n",
      "     - ------------------------------------- 0.6/12.8 MB 853.3 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 0.7/12.8 MB 919.5 kB/s eta 0:00:14\n",
      "     -- ------------------------------------ 0.7/12.8 MB 930.9 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 944.6 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 924.5 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.8/12.8 MB 926.8 kB/s eta 0:00:13\n",
      "     -- ------------------------------------ 0.9/12.8 MB 913.3 kB/s eta 0:00:14\n",
      "     -- ------------------------------------ 0.9/12.8 MB 913.3 kB/s eta 0:00:14\n",
      "     -- ------------------------------------ 0.9/12.8 MB 847.7 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 1.0/12.8 MB 857.9 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.0/12.8 MB 850.4 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.1/12.8 MB 896.4 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.2/12.8 MB 917.5 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.2/12.8 MB 935.3 kB/s eta 0:00:13\n",
      "     --- ----------------------------------- 1.3/12.8 MB 951.5 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 993.8 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 989.8 kB/s eta 0:00:12\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.0 MB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 996.7 kB/s eta 0:00:12\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.0 MB/s eta 0:00:12\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 1.0 MB/s eta 0:00:12\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 1.0 MB/s eta 0:00:11\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ------ --------------------------------- 1.9/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.1 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.1 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 2.2/12.8 MB 1.1 MB/s eta 0:00:10\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.1 MB/s eta 0:00:10\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 2.5/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.7/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.8/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.9/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 3.0/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.5/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.1/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.1/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 4.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.6/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.6/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.8/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 4.8/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.1/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.1/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.1/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 5.1/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.4/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.9/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.9/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.1/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.1/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.2/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.2/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.7/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.7/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.7/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.7/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 7.0/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.0/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.2/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.3/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.5/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.6/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 9.9/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarah\\desktop\\4th-year-solo-project\\.conda\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m padded_pos_tags \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 36\u001b[0m     padded_pos_tags[column] \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\keras_preprocessing\\sequence.py:98\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot understood\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m truncating)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m trunc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m sample_shape:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of sample \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m of sequence at position \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    101\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis different from expected shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    102\u001b[0m                      (trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], idx, sample_shape))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'X'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load SpaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Assuming 'dataset' is your DataFrame with text columns\n",
    "# Convert the text column to string type\n",
    "dataset['text'] = dataset['text'].astype(str)\n",
    "\n",
    "# Iterate through each text column in the DataFrame\n",
    "max_length = 0\n",
    "for column in dataset.columns:\n",
    "    # Tokenize the text in the column and perform POS tagging\n",
    "    pos_tags = []\n",
    "    for text in dataset[column]:\n",
    "        if isinstance(text, str):\n",
    "            doc = nlp(text)\n",
    "            pos_tags.append([token.pos_ for token in doc])\n",
    "            # Update max_length based on the maximum length of sequences\n",
    "            max_length = max(max_length, len(doc))\n",
    "        else:\n",
    "            # Handle non-string values (e.g., integers)\n",
    "            # You may choose to ignore these values or handle them differently based on your requirements\n",
    "            pos_tags.append([])\n",
    "    \n",
    "    # Replace the original text with POS tags in the DataFrame\n",
    "    dataset[column] = pos_tags\n",
    "\n",
    "# Now dataset contains POS tags instead of the original text\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "padded_pos_tags = {}\n",
    "for column in dataset.columns:\n",
    "    padded_pos_tags[column] = pad_sequences(dataset[column], maxlen=max_length, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 140, 50)           1610550   \n",
      "                                                                 \n",
      " cu_dnnlstm_5 (CuDNNLSTM)    (None, 150)               121200    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                9664      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745,639\n",
      "Trainable params: 1,745,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, CuDNNLSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "# Define the vocabulary size based on the actual number of unique words in the training data\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "max_length = 140\n",
    "\n",
    "optimizer = Adam(learning_rate=0.000009)\n",
    "m1 = Sequential()\n",
    "m1.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "m1.add(CuDNNLSTM(units=150))\n",
    "m1.add(Dense(units=64))\n",
    "m1.add(Dense(units=64))\n",
    "m1.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "m1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.6914 - accuracy: 0.5310 - val_loss: 0.6896 - val_accuracy: 0.5368\n",
      "Epoch 2/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6892 - accuracy: 0.5348 - val_loss: 0.6883 - val_accuracy: 0.5368\n",
      "Epoch 3/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6875 - accuracy: 0.5349 - val_loss: 0.6862 - val_accuracy: 0.5370\n",
      "Epoch 4/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6839 - accuracy: 0.5425 - val_loss: 0.6820 - val_accuracy: 0.5427\n",
      "Epoch 5/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6756 - accuracy: 0.5854 - val_loss: 0.6713 - val_accuracy: 0.5950\n",
      "Epoch 6/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6523 - accuracy: 0.6335 - val_loss: 0.6456 - val_accuracy: 0.6422\n",
      "Epoch 7/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.6019 - accuracy: 0.6858 - val_loss: 0.6057 - val_accuracy: 0.6736\n",
      "Epoch 8/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.5525 - accuracy: 0.7258 - val_loss: 0.5872 - val_accuracy: 0.6968\n",
      "Epoch 9/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.5219 - accuracy: 0.7467 - val_loss: 0.5737 - val_accuracy: 0.7066\n",
      "Epoch 10/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4987 - accuracy: 0.7632 - val_loss: 0.5623 - val_accuracy: 0.7157\n",
      "Epoch 11/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4789 - accuracy: 0.7750 - val_loss: 0.5531 - val_accuracy: 0.7208\n",
      "Epoch 12/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4609 - accuracy: 0.7861 - val_loss: 0.5451 - val_accuracy: 0.7284\n",
      "Epoch 13/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4440 - accuracy: 0.7963 - val_loss: 0.5389 - val_accuracy: 0.7332\n",
      "Epoch 14/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5357 - val_accuracy: 0.7337\n",
      "Epoch 15/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4140 - accuracy: 0.8130 - val_loss: 0.5311 - val_accuracy: 0.7394\n",
      "Epoch 16/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.4001 - accuracy: 0.8220 - val_loss: 0.5277 - val_accuracy: 0.7427\n",
      "Epoch 17/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3875 - accuracy: 0.8277 - val_loss: 0.5244 - val_accuracy: 0.7435\n",
      "Epoch 18/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3756 - accuracy: 0.8333 - val_loss: 0.5246 - val_accuracy: 0.7482\n",
      "Epoch 19/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3641 - accuracy: 0.8403 - val_loss: 0.5239 - val_accuracy: 0.7431\n",
      "Epoch 20/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3532 - accuracy: 0.8455 - val_loss: 0.5232 - val_accuracy: 0.7490\n",
      "Epoch 21/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3430 - accuracy: 0.8503 - val_loss: 0.5263 - val_accuracy: 0.7525\n",
      "Epoch 22/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3333 - accuracy: 0.8552 - val_loss: 0.5279 - val_accuracy: 0.7501\n",
      "Epoch 23/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3243 - accuracy: 0.8600 - val_loss: 0.5290 - val_accuracy: 0.7555\n",
      "Epoch 24/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3151 - accuracy: 0.8654 - val_loss: 0.5340 - val_accuracy: 0.7553\n",
      "Epoch 25/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.3066 - accuracy: 0.8698 - val_loss: 0.5362 - val_accuracy: 0.7550\n",
      "Epoch 26/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2982 - accuracy: 0.8725 - val_loss: 0.5381 - val_accuracy: 0.7543\n",
      "Epoch 27/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2902 - accuracy: 0.8774 - val_loss: 0.5484 - val_accuracy: 0.7560\n",
      "Epoch 28/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2826 - accuracy: 0.8813 - val_loss: 0.5513 - val_accuracy: 0.7560\n",
      "Epoch 29/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2758 - accuracy: 0.8852 - val_loss: 0.5560 - val_accuracy: 0.7560\n",
      "Epoch 30/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2687 - accuracy: 0.8891 - val_loss: 0.5641 - val_accuracy: 0.7547\n",
      "Epoch 31/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2618 - accuracy: 0.8917 - val_loss: 0.5675 - val_accuracy: 0.7549\n",
      "Epoch 32/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2553 - accuracy: 0.8952 - val_loss: 0.5760 - val_accuracy: 0.7548\n",
      "Epoch 33/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2488 - accuracy: 0.8982 - val_loss: 0.5796 - val_accuracy: 0.7523\n",
      "Epoch 34/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2429 - accuracy: 0.9010 - val_loss: 0.5899 - val_accuracy: 0.7530\n",
      "Epoch 35/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2371 - accuracy: 0.9035 - val_loss: 0.5993 - val_accuracy: 0.7528\n",
      "Epoch 36/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2313 - accuracy: 0.9067 - val_loss: 0.6064 - val_accuracy: 0.7520\n",
      "Epoch 37/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2261 - accuracy: 0.9097 - val_loss: 0.6184 - val_accuracy: 0.7505\n",
      "Epoch 38/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2209 - accuracy: 0.9121 - val_loss: 0.6240 - val_accuracy: 0.7489\n",
      "Epoch 39/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2156 - accuracy: 0.9140 - val_loss: 0.6365 - val_accuracy: 0.7484\n",
      "Epoch 40/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2107 - accuracy: 0.9164 - val_loss: 0.6461 - val_accuracy: 0.7469\n",
      "Epoch 41/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2060 - accuracy: 0.9173 - val_loss: 0.6559 - val_accuracy: 0.7492\n",
      "Epoch 42/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.2016 - accuracy: 0.9202 - val_loss: 0.6606 - val_accuracy: 0.7462\n",
      "Epoch 43/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1971 - accuracy: 0.9225 - val_loss: 0.6792 - val_accuracy: 0.7469\n",
      "Epoch 44/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1928 - accuracy: 0.9236 - val_loss: 0.6901 - val_accuracy: 0.7448\n",
      "Epoch 45/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1887 - accuracy: 0.9265 - val_loss: 0.6940 - val_accuracy: 0.7460\n",
      "Epoch 46/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1847 - accuracy: 0.9278 - val_loss: 0.7220 - val_accuracy: 0.7426\n",
      "Epoch 47/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1807 - accuracy: 0.9289 - val_loss: 0.7219 - val_accuracy: 0.7418\n",
      "Epoch 48/50\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.1775 - accuracy: 0.9302 - val_loss: 0.7411 - val_accuracy: 0.7433\n",
      "Epoch 49/50\n",
      "497/498 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9321"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m m1\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\Desktop\\4th-year-solo-project\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "m1.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = m1.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 1s 5ms/step\n",
      "Precision: 0.7589\n",
      "Recall: 0.7088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Predict on validation data\n",
    "y_val_pred_prob_m1 = m1.predict(X_test)\n",
    "y_val_pred_m1 = (y_val_pred_prob_m1 > 0.5).astype(int)  # Threshold for binary classification\n",
    "\n",
    "# Assuming y_test is in binary format (0 or 1)\n",
    "y_val_true_m1 = y_test\n",
    "\n",
    "# Calculate precision and recall for binary classification\n",
    "precision_m1 = precision_score(y_val_true_m1, y_val_pred_m1)\n",
    "recall_m1 = recall_score(y_val_true_m1, y_val_pred_m1)\n",
    "\n",
    "# print the results\n",
    "print(f'Precision: {precision_m1:.4f}')\n",
    "print(f'Recall: {recall_m1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
