{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(\"../Datasets/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name_to_remove = 'article_link'\n",
    "dataset = dataset.drop(columns=[column_name_to_remove])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['headline'], dataset['is_sarcastic'], test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#use spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#for padding\n",
    "max_length = 100\n",
    "\n",
    "for text in X_train:\n",
    "    doc = nlp(text)\n",
    "    max_length = max(max_length, len(doc))\n",
    "\n",
    "#iterate through each text column in the datset\n",
    "pos_tag_dict = {'NOUN': 1, 'VERB': 2, 'ADJ': 3, 'ADV': 4, 'ADP': 5, 'PRON': 6, 'DET': 7, 'CONJ': 8, 'NUM': 9, 'PART': 10, 'INTJ': 11, 'SYM': 12, 'X': 13}\n",
    "padded_pos_tags_train = []\n",
    "padded_pos_tags_test = []\n",
    "\n",
    "# POS tagging and padding for training set\n",
    "for text in X_train:\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [pos_tag_dict.get(token.pos_, 0) for token in doc]\n",
    "    padded_pos_tags_train.append(pad_sequences([pos_tags], maxlen=max_length, padding='post')[0])\n",
    "\n",
    "# POS tagging and padding for testing set\n",
    "for text in X_test:\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [pos_tag_dict.get(token.pos_, 0) for token in doc]\n",
    "    padded_pos_tags_test.append(pad_sequences([pos_tags], maxlen=max_length, padding='post')[0])\n",
    "\n",
    "X_train_pos = np.array(padded_pos_tags_train)\n",
    "X_test_pos = np.array(padded_pos_tags_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 100)          1400      \n",
      "                                                                 \n",
      " cu_dnnlstm_3 (CuDNNLSTM)    (None, 150)               151200    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                9664      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,489\n",
      "Trainable params: 166,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "pos_tag_vocab_size = len(pos_tag_dict) + 1\n",
    "\n",
    "max_length = 100\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "m1 = Sequential()\n",
    "m1.add(Embedding(input_dim=pos_tag_vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "m1.add(CuDNNLSTM(units=150))\n",
    "m1.add(Dense(units=64, activation='relu'))\n",
    "m1.add(Dense(units=64, activation='relu'))\n",
    "m1.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "m1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "293/293 [==============================] - 5s 14ms/step - loss: 0.8428 - accuracy: 0.5611 - val_loss: 0.6878 - val_accuracy: 0.5546\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6859 - accuracy: 0.5638 - val_loss: 0.6910 - val_accuracy: 0.5546\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6862 - accuracy: 0.5638 - val_loss: 0.6879 - val_accuracy: 0.5546\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6870 - accuracy: 0.5600 - val_loss: 0.6877 - val_accuracy: 0.5546\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6861 - accuracy: 0.5638 - val_loss: 0.6877 - val_accuracy: 0.5546\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6863 - accuracy: 0.5638 - val_loss: 0.6872 - val_accuracy: 0.5546\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6859 - accuracy: 0.5638 - val_loss: 0.6877 - val_accuracy: 0.5546\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6868 - accuracy: 0.5582 - val_loss: 0.6873 - val_accuracy: 0.5546\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6864 - accuracy: 0.5638 - val_loss: 0.6931 - val_accuracy: 0.5546\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6865 - accuracy: 0.5638 - val_loss: 0.6894 - val_accuracy: 0.5546\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6861 - accuracy: 0.5618 - val_loss: 0.6892 - val_accuracy: 0.5546\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6865 - accuracy: 0.5638 - val_loss: 0.6873 - val_accuracy: 0.5546\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6873 - accuracy: 0.5597 - val_loss: 0.6912 - val_accuracy: 0.5546\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6866 - accuracy: 0.5638 - val_loss: 0.6873 - val_accuracy: 0.5546\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6862 - accuracy: 0.5632 - val_loss: 0.6872 - val_accuracy: 0.5546\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6861 - accuracy: 0.5638 - val_loss: 0.6907 - val_accuracy: 0.5546\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6871 - accuracy: 0.5634 - val_loss: 0.6901 - val_accuracy: 0.5546\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6869 - accuracy: 0.5638 - val_loss: 0.6878 - val_accuracy: 0.5546\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6872 - accuracy: 0.5586 - val_loss: 0.6891 - val_accuracy: 0.5546\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.6868 - accuracy: 0.5638 - val_loss: 0.6877 - val_accuracy: 0.5546\n",
      "251/251 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.5546\n",
      "Loss: 0.6877213716506958, Accuracy: 55.46%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "m1.fit(X_train_pos, y_train, epochs=20, batch_size=64, validation_data=(X_test_pos, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = m1.evaluate(X_test_pos, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "#predict on val data\n",
    "y_val_pred_prob_m1 = m1.predict(X_test)\n",
    "y_val_pred_m1 = (y_val_pred_prob_m1 > 0.5).astype(int)\n",
    "\n",
    "y_val_true_m1 = y_test\n",
    "\n",
    "#calculate precision and recall for binary classification\n",
    "precision_m1 = precision_score(y_val_true_m1, y_val_pred_m1)\n",
    "recall_m1 = recall_score(y_val_true_m1, y_val_pred_m1)\n",
    "\n",
    "# print the results\n",
    "print(f'Precision: {precision_m1:.4f}')\n",
    "print(f'Recall: {recall_m1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
